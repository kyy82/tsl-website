<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Armed Bandit</title>
    <script src="https://cdn.jsdelivr.net/npm/es6-promise@4.2.8/dist/es6-promise.auto.min.js"></script>
    <script src="../scripts/mathjax-config.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.js"></script>
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="../scripts/demotab.css">
    <link rel="stylesheet" href="../demo-common.css">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="iframe-content">
        <div class="container">

        <div class="info-tabs">
            <div class="tab-header">
            </div>
            <div class="tab-content">
                <div class="tab-panel active" data-tab-title="Introduction">
                    <h3>Multi-Armed Bandit Problem</h3>
                    <p>The multi-armed bandit is a classic problem in reinforcement learning that models the exploration vs exploitation dilemma. Imagine you're in a casino with multiple slot machines ("one-armed bandits"), each with unknown payout rates.</p>

                    <p>This problem appears everywhere:</p>
                    <ul>
                        <li><strong>A/B Testing</strong> - Which website design performs better?</li>
                        <li><strong>Clinical Trials</strong> - Which treatment should we give to patients?</li>
                        <li><strong>Online Advertising</strong> - Which ad gets more clicks?</li>
                        <li><strong>Resource Allocation</strong> - Where should we invest limited resources?</li>
                    </ul>

                    <p>The key challenge: <em>Should you exploit what you know works, or explore to potentially find something better?</em></p>
                </div>

                <div class="tab-panel" data-tab-title="Theory">
                    <h3>Mathematical Framework</h3>

                    <p>At each time step $t$, you choose an action $a_t$ and receive reward $r_t$. The goal is to maximize cumulative reward over time.</p>

                    <p><strong>Key Concepts:</strong></p>
                    <ul>
                        <li><strong>Action Value:</strong> $q^*(a) = \mathbb{E}[r_t | a_t = a]$ - true expected reward</li>
                        <li><strong>Estimated Value:</strong> $Q_t(a) = \frac{1}{N_t(a)} \sum_{i=1}^t r_i \mathbf{1}_{a_i = a}$ - sample average</li>
                        <li><strong>Regret:</strong> $L_t = \sum_{i=1}^t (q^*(a^*) - q^*(a_i))$ - cumulative opportunity cost</li>
                    </ul>

                    <p><strong>Epsilon-Greedy Algorithm:</strong></p>
                    <div class="equation-block">
                        $$a_t = \begin{cases}
                        \arg\max_a Q_t(a) & \text{with probability } 1-\epsilon \\
                        \text{random action} & \text{with probability } \epsilon
                        \end{cases}$$
                    </div>

                    <p>Where $\epsilon \in [0,1]$ controls the exploration rate:</p>
                    <ul>
                        <li>$\epsilon = 0$: Pure exploitation (greedy)</li>
                        <li>$\epsilon = 1$: Pure exploration (random)</li>
                        <li>$\epsilon = 0.1$: 90% exploitation, 10% exploration</li>
                    </ul>

                    <p><strong>Why it works:</strong> As $t \to \infty$, we explore all actions infinitely often, so $Q_t(a) \to q^*(a)$ and the algorithm finds the optimal action.</p>
                </div>

                <div class="tab-panel" data-tab-title="Instructions">
                    <h3>How to Use This Demo</h3>

                    <p><strong>Interactive Learning:</strong></p>
                    <ul>
                        <li><strong>Pull arms</strong> - Click the "Pull Arm" buttons to try different arms (50 pulls total)</li>
                        <li><strong>Watch statistics</strong> - Observe total reward, number of pulls, and mean reward for each arm</li>
                        <li><strong>Develop strategy</strong> - Try to maximize your total reward</li>
                        <li><strong>Reset game</strong> - Start over with the same arm distributions</li>
                    </ul>

                    <p><strong>Algorithm Demonstrations:</strong></p>
                    <ul>
                        <li><strong>"Show Exploration Phase"</strong> - Watch how epsilon-greedy learns the arm values</li>
                        <li><strong>"Show Trained Performance"</strong> - See how the algorithm performs after learning</li>
                        <li><strong>"Reveal True Distributions"</strong> - Discover the actual reward probabilities</li>
                    </ul>

                    <p><strong>Visual Guide:</strong></p>
                    <ul>
                        <li><strong>Total Reward:</strong> Sum of all rewards received from this arm</li>
                        <li><strong>Number of Pulls:</strong> How many times you've tried this arm</li>
                        <li><strong>Mean Reward:</strong> Average reward per pull (estimated value)</li>
                    </ul>
                </div>

                <div class="tab-panel" data-tab-title="Tips">
                    <h3>Strategy and Insights</h3>

                    <p><strong>Human vs Algorithm:</strong></p>
                    <ul>
                        <li>Try playing first, then compare with the epsilon-greedy algorithm</li>
                        <li>Humans often explore too little ("hot hand fallacy") or too much (overthinking)</li>
                        <li>The algorithm balances exploration and exploitation mathematically</li>
                    </ul>

                    <p><strong>Key Insights:</strong></p>
                    <ul>
                        <li><strong>Early exploration matters</strong> - Don't commit too quickly to one arm</li>
                        <li><strong>Sample size affects confidence</strong> - More pulls give better estimates</li>
                        <li><strong>Opportunity cost is real</strong> - Every suboptimal choice costs potential reward</li>
                        <li><strong>Perfect information is impossible</strong> - You must act with uncertainty</li>
                    </ul>

                    <p><strong>Real-world Applications:</strong></p>
                    <ul>
                        <li>Start with some exploration to gather data</li>
                        <li>Gradually shift toward exploitation as confidence grows</li>
                        <li>Consider the cost of exploration vs potential gains</li>
                        <li>Monitor for changes in the environment (non-stationary bandits)</li>
                    </ul>

                    <p><strong>Advanced Concepts:</strong></p>
                    <ul>
                        <li><strong>Upper Confidence Bound (UCB)</strong> - More sophisticated than epsilon-greedy</li>
                        <li><strong>Thompson Sampling</strong> - Bayesian approach to exploration</li>
                        <li><strong>Contextual Bandits</strong> - Actions depend on observed context</li>
                        <li><strong>Non-stationary Bandits</strong> - Reward distributions change over time</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- User Play Section - Top -->
        <div class="user-play-section">
            <h3 style="text-align: center; margin-bottom: 20px;">Interactive Arms - Try Your Strategy!</h3>
            <div class="arms-container">
                <div class="arm-section">
                    <h4>Arm 1</h4>
                    <button class="arm-button arm1-btn" id="arm1-btn" onclick="pullArm(1)">
                        Pull Arm 1
                    </button>
                    <div class="stats-box" id="arm1-stats">
                        <div class="stat-item">
                            <span class="stat-label">Total Reward:</span>
                            <span class="stat-value" id="arm1-total">0</span>
                        </div>
                        <div class="stat-item">
                            <span class="stat-label">Number of Pulls:</span>
                            <span class="stat-value" id="arm1-count">0</span>
                        </div>
                        <div class="stat-item">
                            <span class="stat-label">Mean Reward:</span>
                            <span class="stat-value" id="arm1-mean">0.00</span>
                        </div>
                    </div>
                </div>

                <div class="arm-section">
                    <h4>Arm 2</h4>
                    <button class="arm-button arm2-btn" id="arm2-btn" onclick="pullArm(2)">
                        Pull Arm 2
                    </button>
                    <div class="stats-box" id="arm2-stats">
                        <div class="stat-item">
                            <span class="stat-label">Total Reward:</span>
                            <span class="stat-value" id="arm2-total">0</span>
                        </div>
                        <div class="stat-item">
                            <span class="stat-label">Number of Pulls:</span>
                            <span class="stat-value" id="arm2-count">0</span>
                        </div>
                        <div class="stat-item">
                            <span class="stat-label">Mean Reward:</span>
                            <span class="stat-value" id="arm2-mean">0.00</span>
                        </div>
                    </div>
                </div>

                <div class="arm-section">
                    <h4>Arm 3</h4>
                    <button class="arm-button arm3-btn" id="arm3-btn" onclick="pullArm(3)">
                        Pull Arm 3
                    </button>
                    <div class="stats-box" id="arm3-stats">
                        <div class="stat-item">
                            <span class="stat-label">Total Reward:</span>
                            <span class="stat-value" id="arm3-total">0</span>
                        </div>
                        <div class="stat-item">
                            <span class="stat-label">Number of Pulls:</span>
                            <span class="stat-value" id="arm3-count">0</span>
                        </div>
                        <div class="stat-item">
                            <span class="stat-label">Mean Reward:</span>
                            <span class="stat-value" id="arm3-mean">0.00</span>
                        </div>
                    </div>
                </div>
            </div>

            <div style="text-align: center; margin: 20px 0;">
                <p><strong>Total Rewards:</strong> <span id="total-rewards" style="font-family: monospace; font-size: 18px; font-weight: bold; color: #007bff;">0</span></p>
                <p><strong>Total Pulls:</strong> <span id="total-pulls">0</span> / 50</p>
                <button class="demo-button" onclick="resetUserSession()" style="background: #6c757d; color: white;">Reset Game</button>
            </div>
        </div>

        <!-- Algorithm Demonstration Section - Bottom -->
        <div class="demo-area">
            <div class="demo-controls">
                <h3>Algorithm Demonstrations</h3>
                <p>See how the epsilon-greedy algorithm tackles this problem:</p>

                <button class="demo-button explore-btn" id="explore-btn" onclick="demonstrateExploration()">
                    Show Exploration Phase
                </button>

                <button class="demo-button trained-btn" id="trained-btn" onclick="demonstrateTrained()">
                    Show Trained Performance
                </button>

                <button class="demo-button reveal-btn" id="reveal-btn" onclick="revealDistributions()">
                    Reveal True Distributions
                </button>

                <div class="results-container" id="results-container" style="display: none;">
                    <div class="result-panel" id="exploration-results">
                        <h4>Exploration Phase</h4>
                        <div class="progress-bar">
                            <div class="progress-fill" id="exploration-progress"></div>
                        </div>
                        <div class="algorithm-display" id="exploration-display">
                            Ready to start exploration...
                        </div>
                        <div class="chart-container" style="position: relative; height: 250px; margin-top: 10px;">
                            <canvas id="exploration-chart"></canvas>
                        </div>
                    </div>

                    <div class="result-panel" id="performance-results">
                        <h4>Algorithm Performance</h4>
                        <div class="algorithm-display" id="performance-display">
                            Algorithm estimates will appear here...
                        </div>
                    </div>
                </div>

                <div class="result-panel hidden" id="distribution-reveal">
                    <h4>True Distributions Revealed</h4>
                    <div class="algorithm-display" id="distribution-display">
                        True probability distributions will be shown here...
                    </div>
                </div>
            </div>
        </div>

        </div>
    </div>

    <script src="../scripts/demotab.js"></script>
    <script src="bandit-engine.js"></script>
    <script src="script.js?v=1.0"></script>
    <script>
        // Force layout recalculation on page load to fix positioning
        document.addEventListener('DOMContentLoaded', function() {
            setTimeout(function() {
                const demoControls = document.querySelector('.demo-controls');
                const resultsContainer = document.getElementById('results-container');
                if (demoControls && resultsContainer) {
                    // Force reflow by accessing layout properties
                    demoControls.offsetHeight;
                    resultsContainer.offsetHeight;
                    // Trigger style recalculation
                    demoControls.style.display = 'block';
                    resultsContainer.style.display = resultsContainer.style.display;
                }
            }, 100);
        });
    </script>
</body>
</html>